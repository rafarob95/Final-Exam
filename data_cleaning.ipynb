{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e585b74-2eda-4287-b589-e044279ef262",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RegionID  SizeRank       RegionName RegionType StateName    BaseDate  \\\n",
      "0    102001         0    United States    country       NaN  2024-02-29   \n",
      "1    394913         1     New York, NY        msa        NY  2024-02-29   \n",
      "2    753899         2  Los Angeles, CA        msa        CA  2024-02-29   \n",
      "3    394463         3      Chicago, IL        msa        IL  2024-02-29   \n",
      "4    394514         4       Dallas, TX        msa        TX  2024-02-29   \n",
      "\n",
      "   2024-03-31  2024-05-31  2025-02-28  \n",
      "0         0.8         2.2         0.6  \n",
      "1         0.5         1.0        -1.6  \n",
      "2         1.0         2.3        -0.9  \n",
      "3         1.1         3.0        -1.0  \n",
      "4         1.1         2.8         0.8  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "# 1.⁠ ⁠mortgage: calculated\n",
    "\n",
    "# 2.⁠ ⁠rentals: ZORI(smoothed): all homes plus multifamily time series - metro&us\n",
    "# The index is dollar-denominated by computing the mean of listed rents that fall \n",
    "# into the 40th to 60th percentile range for all homes and apartments in a given\n",
    "# region, which is weighted to reflect the rental housing stock.\n",
    "rentals = pd.read_csv(\"data/Dataset to use/Metro_zori_uc_sfrcondomfr_sm_month.csv\")\n",
    "# print(rentals.head())\n",
    "\n",
    "# 3.⁠ ⁠SALES: median sale price (smooth, all homes, monthly) - metro&us\n",
    "# The Sales Count Nowcast is the estimated number of unique properties that sold \n",
    "# during the month after accounting for the latency between when sales occur and \n",
    "# when they are reported. Available only for the raw cut of all homes.\n",
    "# Sale Price (median/mean): The price at which homes across various geographies were sold.\n",
    "# Sale-to-List Ratio (mean/median): Ratio of sale vs. final list price.\n",
    "# Percent of Sales Below/Above List: Share of sales where sale price below/above the \n",
    "# final list price; excludes homes sold for exactly the list price.\n",
    "median_sales = pd.read_csv(\"data/Dataset to use/Metro_median_sale_price_uc_sfrcondo_sm_month.csv\")\n",
    "# print(median_sales.head())\n",
    "\n",
    "# 4.⁠ ⁠ZHVF (Forecast), All homes (SFR, condo/co-op), raw, mid-tier - metro & us\n",
    "# A month-ahead, quarter-ahead and year-ahead forecast of the Zillow Home Value Index (ZHVI).\n",
    "home_forecast = pd.read_csv(\"data/Dataset to use/Metro_zhvf_growth_uc_sfrcondo_tier_0.33_0.67_month.csv\")\n",
    "print(home_forecast.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74067e28-4760-49db-8358-7973ee579a27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RegionID  SizeRank      Region Name Region Type  State Name Date Recorded  \\\n",
      "1    394913         1     New York, NY         msa    New York    2015-01-31   \n",
      "2    753899         2  Los Angeles, CA         msa  California    2015-01-31   \n",
      "3    394463         3      Chicago, IL         msa    Illinois    2015-01-31   \n",
      "4    394514         4       Dallas, TX         msa       Texas    2015-01-31   \n",
      "5    394692         5      Houston, TX         msa       Texas    2015-01-31   \n",
      "\n",
      "   Monthly Rent  \n",
      "1   2286.918320  \n",
      "2   1833.212831  \n",
      "3   1418.891001  \n",
      "4   1104.552997  \n",
      "5   1226.598136  \n"
     ]
    }
   ],
   "source": [
    "# Data cleaning for rentals dataset \n",
    "\n",
    "# missing value check\n",
    "rentals.dropna(subset=['RegionID', 'RegionName'], inplace=True)\n",
    "\n",
    "# long format \n",
    "rentals_melted = rentals.melt(id_vars=[\"RegionID\", \"SizeRank\", \"RegionName\", \"RegionType\", \"StateName\"],\n",
    "                              var_name=\"Date\",\n",
    "                              value_name=\"Rent\")\n",
    "\n",
    "# Convert 'Date' to datetime format\n",
    "rentals_melted['Date'] = pd.to_datetime(rentals_melted['Date'], errors='coerce')\n",
    "\n",
    "# Drop rows where 'Rent' is null\n",
    "rentals_melted.dropna(subset=['Rent'], inplace=True)\n",
    "\n",
    "\n",
    "# Drop all rows where RegionType is country\n",
    "state_rentals = rentals_melted[rentals_melted['RegionType'] != 'country']\n",
    "\n",
    "state_rentals = state_rentals.copy()\n",
    "state_rentals.rename(columns={\n",
    "    'RegionName': 'Region Name',\n",
    "    'RegionType': 'Region Type',\n",
    "    'StateName': 'State Name',\n",
    "    'Date': 'Date Recorded',\n",
    "    'Rent': 'Monthly Rent'\n",
    "}, inplace=True)\n",
    "\n",
    "state_abbreviations = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California', 'CO': 'Colorado',\n",
    "    'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho',\n",
    "    'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana',\n",
    "    'ME': 'Maine', 'MD': 'Maryland', 'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi',\n",
    "    'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico', 'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont', 'VA': 'Virginia',\n",
    "    'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "# Replace state abbreviations with full names in the 'State Name' column\n",
    "state_rentals['State Name'] = state_rentals['State Name'].map(state_abbreviations).fillna(state_rentals['State Name'])\n",
    "\n",
    "\n",
    "print(state_rentals.head())\n",
    "\n",
    "state_rentals.to_csv(\"Cleaned_Data/cleaned_state_rentals.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f1753a-1232-4ee4-8321-ec483ed3cfa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RegionID  SizeRank      Region Name Region Type  State Name Date Recorded  \\\n",
      "1    394913         1     New York, NY         msa    New York    2008-04-30   \n",
      "2    753899         2  Los Angeles, CA         msa  California    2008-04-30   \n",
      "3    394463         3      Chicago, IL         msa    Illinois    2008-04-30   \n",
      "4    394514         4       Dallas, TX         msa       Texas    2008-04-30   \n",
      "5    394692         5      Houston, TX         msa       Texas    2008-04-30   \n",
      "\n",
      "   Median Sale Price  \n",
      "1           395000.0  \n",
      "2           461000.0  \n",
      "3           227333.0  \n",
      "4           142967.0  \n",
      "5           145788.0  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'Date' to datetime format\n",
    "median_sales_melted = median_sales.melt(id_vars=[\"RegionID\", \"SizeRank\", \"RegionName\", \"RegionType\", \"StateName\"],\n",
    "                                        var_name=\"Date\",\n",
    "                                        value_name=\"MedianSalePrice\")\n",
    "median_sales_melted['Date'] = pd.to_datetime(median_sales_melted['Date'], errors='coerce')\n",
    "\n",
    "# Drop rows where 'MedianSalePrice' is null\n",
    "median_sales_melted.dropna(subset=['MedianSalePrice'], inplace=True)\n",
    "\n",
    "# Drop all rows where RegionType is country\n",
    "state_median_sales = median_sales_melted[median_sales_melted['RegionType'] != 'country']\n",
    "state_median_sales = state_median_sales.copy()\n",
    "\n",
    "# Rename columns\n",
    "state_median_sales.rename(columns={\n",
    "    'RegionName': 'Region Name',\n",
    "    'RegionType': 'Region Type',\n",
    "    'StateName': 'State Name',\n",
    "    'Date': 'Date Recorded',\n",
    "    'MedianSalePrice': 'Median Sale Price'\n",
    "}, inplace=True)\n",
    "\n",
    "# Full state names\n",
    "state_abbreviations = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California', 'CO': 'Colorado',\n",
    "    'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho',\n",
    "    'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana',\n",
    "    'ME': 'Maine', 'MD': 'Maryland', 'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi',\n",
    "    'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico', 'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont', 'VA': 'Virginia',\n",
    "    'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming'\n",
    "}\n",
    "state_median_sales['State Name'] = state_median_sales['State Name'].map(state_abbreviations).fillna(state_median_sales['State Name'])\n",
    "\n",
    "print(state_median_sales.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f243282e-0093-4433-a7ab-54489ade4b96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RegionID  SizeRank      Region Name Region Type  State Name  \\\n",
      "1    394913         1     New York, NY         msa    New York   \n",
      "2    753899         2  Los Angeles, CA         msa  California   \n",
      "3    394463         3      Chicago, IL         msa    Illinois   \n",
      "4    394514         4       Dallas, TX         msa       Texas   \n",
      "5    394692         5      Houston, TX         msa       Texas   \n",
      "\n",
      "  Base Date Recorded Forecast Date  Forecast Growth (%)  \n",
      "1         2024-02-29    2024-03-31                  0.5  \n",
      "2         2024-02-29    2024-03-31                  1.0  \n",
      "3         2024-02-29    2024-03-31                  1.1  \n",
      "4         2024-02-29    2024-03-31                  1.1  \n",
      "5         2024-02-29    2024-03-31                  0.8  \n"
     ]
    }
   ],
   "source": [
    "# Long format\n",
    "home_forecast_melted = home_forecast.melt(id_vars=[\"RegionID\", \"SizeRank\", \"RegionName\", \"RegionType\", \"StateName\", \"BaseDate\"],\n",
    "                                          var_name=\"ForecastDate\",\n",
    "                                          value_name=\"ForecastGrowth\")\n",
    "\n",
    "# Datetime\n",
    "home_forecast_melted['BaseDate'] = pd.to_datetime(home_forecast_melted['BaseDate'], errors='coerce')\n",
    "home_forecast_melted['ForecastDate'] = pd.to_datetime(home_forecast_melted['ForecastDate'], errors='coerce')\n",
    "\n",
    "# Drop rows where 'ForecastGrowth' is null\n",
    "home_forecast_melted.dropna(subset=['ForecastGrowth'], inplace=True)\n",
    "\n",
    "# Drop all rows where RegionType is country\n",
    "state_home_forecast = home_forecast_melted[home_forecast_melted['RegionType'] != 'country']\n",
    "state_home_forecast = state_home_forecast.copy()\n",
    "\n",
    "# Rename columns\n",
    "state_home_forecast.rename(columns={\n",
    "    'RegionName': 'Region Name',\n",
    "    'RegionType': 'Region Type',\n",
    "    'StateName': 'State Name',\n",
    "    'BaseDate': 'Base Date Recorded',\n",
    "    'ForecastDate': 'Forecast Date',\n",
    "    'ForecastGrowth': 'Forecast Growth (%)'\n",
    "}, inplace=True)\n",
    "\n",
    "# Full state names\n",
    "state_abbreviations = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California', 'CO': 'Colorado',\n",
    "    'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho',\n",
    "    'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana',\n",
    "    'ME': 'Maine', 'MD': 'Maryland', 'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi',\n",
    "    'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico', 'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont', 'VA': 'Virginia',\n",
    "    'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming'\n",
    "}\n",
    "state_home_forecast['State Name'] = state_home_forecast['State Name'].map(state_abbreviations).fillna(state_home_forecast['State Name'])\n",
    "\n",
    "state_home_forecast.to_csv(\"Cleaned_Data/cleaned_state_home_forecast.csv\", index=False)\n",
    "\n",
    "print(state_home_forecast.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3b5bd95-2c08-4a23-857e-df0d0f9a3f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RegionID  SizeRank      Region Name Region Type  State Name Date Recorded  \\\n",
      "0    394913         1     New York, NY         msa    New York    2008-04-30   \n",
      "1    753899         2  Los Angeles, CA         msa  California    2008-04-30   \n",
      "2    394463         3      Chicago, IL         msa    Illinois    2008-04-30   \n",
      "3    394514         4       Dallas, TX         msa       Texas    2008-04-30   \n",
      "4    394692         5      Houston, TX         msa       Texas    2008-04-30   \n",
      "\n",
      "   Median Sale Price               Coordinates   Latitude   Longitude  \n",
      "0           395000.0   (42.165726, -74.948051)  42.165726  -74.948051  \n",
      "1           461000.0  (36.116203, -119.681564)  36.116203 -119.681564  \n",
      "2           227333.0   (40.349457, -88.986137)  40.349457  -88.986137  \n",
      "3           142967.0   (31.054487, -97.563461)  31.054487  -97.563461  \n",
      "4           145788.0   (31.054487, -97.563461)  31.054487  -97.563461  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dictionary of state names to their approximate geographic center coordinates\n",
    "state_coords = {\n",
    "    'Alabama': (32.806671, -86.791130),\n",
    "    # 'Alaska': (61.370716, -152.404419),\n",
    "    'Arizona': (33.729759, -111.431221),\n",
    "    'Arkansas': (34.969704, -92.373123),\n",
    "    'California': (36.116203, -119.681564),\n",
    "    'Colorado': (39.059811, -105.311104),\n",
    "    'Connecticut': (41.597782, -72.755371),\n",
    "    'Delaware': (39.318523, -75.507141),\n",
    "    'Florida': (27.766279, -81.686783),\n",
    "    'Georgia': (33.040619, -83.643074),\n",
    "    # 'Hawaii': (21.094318, -157.498337),\n",
    "    'Idaho': (44.240459, -114.478828),\n",
    "    'Illinois': (40.349457, -88.986137),\n",
    "    'Indiana': (39.849426, -86.258278),\n",
    "    'Iowa': (42.011539, -93.210526),\n",
    "    'Kansas': (38.526600, -96.726486),\n",
    "    'Kentucky': (37.668140, -84.670067),\n",
    "    'Louisiana': (31.169546, -91.867805),\n",
    "    'Maine': (44.693947, -69.381927),\n",
    "    'Maryland': (39.063946, -76.802101),\n",
    "    'Massachusetts': (42.230171, -71.530106),\n",
    "    'Michigan': (43.326618, -84.536095),\n",
    "    'Minnesota': (45.694454, -93.900192),\n",
    "    'Mississippi': (32.741646, -89.678696),\n",
    "    'Missouri': (38.456085, -92.288368),\n",
    "    'Montana': (46.921925, -110.454353),\n",
    "    'Nebraska': (41.125370, -98.268082),\n",
    "    'Nevada': (38.313515, -117.055374),\n",
    "    'New Hampshire': (43.452492, -71.563896),\n",
    "    'New Jersey': (40.298904, -74.521011),\n",
    "    'New Mexico': (34.840515, -106.248482),\n",
    "    'New York': (42.165726, -74.948051),\n",
    "    'North Carolina': (35.630066, -79.806419),\n",
    "    'North Dakota': (47.528912, -99.784012),\n",
    "    'Ohio': (40.388783, -82.764915),\n",
    "    'Oklahoma': (35.565342, -96.928917),\n",
    "    'Oregon': (44.572021, -122.070938),\n",
    "    'Pennsylvania': (40.590752, -77.209755),\n",
    "    'Rhode Island': (41.680893, -71.511780),\n",
    "    'South Carolina': (33.856892, -80.945007),\n",
    "    'South Dakota': (44.299782, -99.438828),\n",
    "    'Tennessee': (35.747845, -86.692345),\n",
    "    'Texas': (31.054487, -97.563461),\n",
    "    'Utah': (40.150032, -111.862434),\n",
    "    'Vermont': (44.045876, -72.710686),\n",
    "    'Virginia': (37.769337, -78.169968),\n",
    "    'Washington': (47.400902, -121.490494),\n",
    "    'West Virginia': (38.491226, -80.954570),\n",
    "    'Wisconsin': (44.268543, -89.616508),\n",
    "    'Wyoming': (42.755966, -107.302490)\n",
    "}\n",
    "\n",
    "\n",
    "coords_df = pd.DataFrame(list(state_coords.items()), columns=['State Name', 'Coordinates'])\n",
    "\n",
    "# Split the 'Coordinates' column into two separate columns for latitude and longitude\n",
    "coords_df[['Latitude', 'Longitude']] = pd.DataFrame(coords_df['Coordinates'].tolist(), index=coords_df.index)\n",
    "\n",
    "state_rentals = pd.merge(state_rentals, coords_df, on='State Name', how='left')\n",
    "\n",
    "state_rentals.to_csv(\"Cleaned_Data/cleaned_state_rentals.csv\", index=False)\n",
    "\n",
    "state_median_sales = pd.merge(state_median_sales, coords_df, on='State Name', how='left')\n",
    "\n",
    "state_median_sales.to_csv(\"Cleaned_Data/cleaned_median_sales.csv\", index=False)\n",
    "\n",
    "print(state_median_sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e35f90a-6fe6-4038-9868-a54afed70368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New York' 'California' 'Illinois' 'Texas' 'Virginia' 'Pennsylvania'\n",
      " 'Florida' 'Georgia' 'Massachusetts' 'Arizona' 'Michigan' 'Washington'\n",
      " 'Minnesota' 'Colorado' 'Maryland' 'Missouri' 'North Carolina' 'Oregon'\n",
      " 'Ohio' 'Nevada' 'Indiana' 'Tennessee' 'Rhode Island' 'Wisconsin'\n",
      " 'Oklahoma' 'Kentucky' 'Louisiana' 'Utah' 'Connecticut' 'Alabama'\n",
      " 'Nebraska' 'South Carolina' 'New Mexico' 'Idaho' 'Arkansas' 'Iowa'\n",
      " 'Kansas' 'Maine' 'New Hampshire' 'Mississippi' 'Delaware' 'New Jersey'\n",
      " 'Montana' 'Wyoming' 'South Dakota' 'North Dakota' 'West Virginia'\n",
      " 'Vermont']\n",
      "['New York' 'California' 'Illinois' 'Texas' 'Virginia' 'Pennsylvania'\n",
      " 'Florida' 'Georgia' 'Massachusetts' 'Arizona' 'Michigan' 'Washington'\n",
      " 'Minnesota' 'Colorado' 'Maryland' 'Missouri' 'North Carolina' 'Oregon'\n",
      " 'Ohio' 'Nevada' 'Indiana' 'Tennessee' 'Rhode Island' 'Wisconsin'\n",
      " 'Oklahoma' 'Kentucky' 'Louisiana' 'Utah' 'Connecticut' 'Alabama'\n",
      " 'Nebraska' 'South Carolina' 'New Mexico' 'Idaho' 'Arkansas' 'Iowa'\n",
      " 'Kansas' 'Mississippi' 'Maine' 'New Hampshire' 'Delaware' 'New Jersey'\n",
      " 'West Virginia' 'North Dakota' 'Vermont' 'Montana' 'Wyoming'\n",
      " 'South Dakota']\n"
     ]
    }
   ],
   "source": [
    "## Datasets with hawaii and alaska dropped for geographical plotting\n",
    "\n",
    "# exclude Hawaii and Alaska for state_rentals\n",
    "state_rentals_without_hawaii_alaska = state_rentals[~state_rentals['State Name'].isin(['Hawaii', 'Alaska'])]\n",
    "\n",
    "state_rentals_without_hawaii_alaska.to_csv(\"Cleaned_Data/state_rentals_excluding_hawaii_alaska.csv\", index=False)\n",
    "\n",
    "median_sales_without_hawaii_alaska = state_median_sales[~state_median_sales['State Name'].isin(['Hawaii', 'Alaska'])]\n",
    "\n",
    "median_sales_without_hawaii_alaska.to_csv(\"Cleaned_Data/median_sales_excluding_hawaii_alaska.csv\", index=False)\n",
    "\n",
    "print(state_rentals_without_hawaii_alaska['State Name'].unique())\n",
    "print(median_sales_without_hawaii_alaska['State Name'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa87bf1-422b-455e-ad18-dbba86ea2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data cleaning for future values dataset \n",
    "future = pd.read_csv('data/Dataset to use/Metro_zhvf_growth_uc_sfrcondo_tier_0.33_0.67_month.csv')\n",
    "# future.head()\n",
    "\n",
    "missing_data = future.isnull().sum()\n",
    "\n",
    "# Convert 'BaseDate' column to datetime\n",
    "future['BaseDate'] = pd.to_datetime(future['BaseDate'])\n",
    "\n",
    "# Renaming columns\n",
    "future.rename(columns={\n",
    "    '2024-03-31': 'March_2024_Forecast',\n",
    "    '2024-05-31': 'May_2024_Forecast',\n",
    "    '2025-02-28': 'February_2025_Forecast'\n",
    "}, inplace=True)\n",
    "\n",
    "# Dropping country values\n",
    "future = future[future['RegionType'] != 'country']\n",
    "\n",
    "future.head(), missing_data\n",
    "\n",
    "future.to_csv(\"Cleaned_Data/cleaned_future_sales.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34934a5b-58b5-406d-8d55-d3815cb39bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data = pd.read_excel('data/uscities.xlsx')\n",
    "\n",
    "city_data = city_data.drop(columns=[col for col in city_data.columns if col not in ['city', 'lat', 'lng', 'state_name']])\n",
    "\n",
    "# Ensure the city and state names in both datasets are ready for merging\n",
    "state_median_sales['city'] = state_median_sales['Region Name'].str.extract(r'^([^,]+),')[0]  # Extract city names\n",
    "state_median_sales['state_name'] = state_median_sales['State Name']  # Ensure state names are aligned\n",
    "\n",
    "# You mentioned city_data is ready with 'city' and 'state_name' columns, so we can proceed directly\n",
    "\n",
    "# Merge the datasets on both 'city' and 'state_name'\n",
    "merged_df = pd.merge(state_median_sales, city_data, on=['city', 'state_name'], how='left')\n",
    "\n",
    "# Check the merge result\n",
    "# print(merged_df.head())\n",
    "\n",
    "# If needed, filter by any specific conditions or dates\n",
    "# For example, to filter by year 2023 as in previous contexts\n",
    "merged_df['Date Recorded'] = pd.to_datetime(merged_df['Date Recorded'])\n",
    "merged_df_2023 = merged_df[merged_df['Date Recorded'].dt.year == 2023]\n",
    "\n",
    "merged_df_2023 = merged_df_2023.dropna(subset=['lat', 'lng'])\n",
    "\n",
    "state_rentals['city'] = state_rentals['Region Name'].str.extract(r'^([^,]+),')[0]\n",
    "state_rentals['state_name'] = state_rentals['State Name']\n",
    "\n",
    "merged_rentals = pd.merge(state_rentals, city_data, on=['city', 'state_name'], how='left')\n",
    "merged_rentals_cleaned = merged_rentals.dropna(subset=['lat', 'lng'])\n",
    "merged_rentals_cleaned = merged_rentals_cleaned[merged_rentals_cleaned['Date Recorded'].dt.year == 2023]\n",
    "# Dropping outlier where rent average is 16,000 a month in 2023\n",
    "merged_rentals_cleaned = merged_rentals_cleaned[merged_rentals_cleaned['Region Name'] != 'Glenwood Springs, CO']\n",
    "\n",
    "merged_rentals_cleaned.head()\n",
    "merged_rentals_cleaned.to_csv(\"Cleaned_Data/2023_rental_price_city.csv\")\n",
    "# Display the head of the merged data to check correctness\n",
    "# print(merged_df_2023.head())\n",
    "# merged_df_2023.to_csv(\"Cleaned_Data/2023_sale_price.csv\")\n",
    "# print(state_rentals.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95ca6105-f445-4ca7-9fff-8c9e9c884bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nq/x683qlmx39ng8v_l8ymc6cw00000gn/T/ipykernel_65183/3313705730.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  state_rentals_without_hawaii_alaska['Date Recorded'] = pd.to_datetime(state_rentals_without_hawaii_alaska['Date Recorded'])\n"
     ]
    }
   ],
   "source": [
    "state_rentals_without_hawaii_alaska['Date Recorded'] = pd.to_datetime(state_rentals_without_hawaii_alaska['Date Recorded'])\n",
    "state_rentals_without_hawaii_alaska = state_rentals_without_hawaii_alaska[state_rentals_without_hawaii_alaska['Date Recorded'].dt.year == 2023]\n",
    "\n",
    "state_rentals_without_hawaii_alaska.to_csv(\"Cleaned_Data/2023_rental_price.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42f73ae1-6bed-4735-b334-60e7c9c642a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nq/x683qlmx39ng8v_l8ymc6cw00000gn/T/ipykernel_65183/2576744259.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  median_sales_without_hawaii_alaska['Date Recorded'] = pd.to_datetime(median_sales_without_hawaii_alaska['Date Recorded'])\n"
     ]
    }
   ],
   "source": [
    "median_sales_without_hawaii_alaska['Date Recorded'] = pd.to_datetime(median_sales_without_hawaii_alaska['Date Recorded'])\n",
    "median_sales_without_hawaii_alaska = median_sales_without_hawaii_alaska[median_sales_without_hawaii_alaska['Date Recorded'].dt.year == 2023]\n",
    "\n",
    "median_sales_without_hawaii_alaska.to_csv(\"Cleaned_Data/2023_sales_state.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba53867-9dbc-462b-8e52-60cb01cdf1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9abcc-1efd-440f-9417-7a9c3c9c4e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
